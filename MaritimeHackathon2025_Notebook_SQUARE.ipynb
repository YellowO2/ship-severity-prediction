{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vessel Deficiency Severity Prediction\n",
    "\n",
    "### Authors:\n",
    "\n",
    "## Sections\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 1: Logic for Deriving a Consensus Severity**\n",
    "\n",
    "In this section, we will explore the dataset and develop a suitable logic for deriving the consensus severity for each deficiency. This involves understanding the text data and finding ways to derive a unified severity rating from multiple annotations provided by Subject Matter Experts (SMEs).\n",
    "\n",
    "#### **Objective of Part 1**:\n",
    "- Understand the deficiency text, which includes descriptions, root causes, corrective actions, and preventive measures.\n",
    "- Derive a consensus severity (High, Medium, Low) for each deficiency based on the ratings given by at least three annotators.\n",
    "\n",
    "#### **Key Tasks**:\n",
    "1. **Explore the Dataset**: Investigate the structure and content of the provided data, focusing on deficiency descriptions and severity annotations.\n",
    "2. **Preprocess the Data**: Clean and prepare the data for analysis, including any necessary text preprocessing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 2: Model Development and Severity Prediction**\n",
    "\n",
    "In this section, we will take the processed data from Part 1 and build a machine learning model to predict the severity of deficiencies.\n",
    "\n",
    "#### **Key Tasks**:\n",
    "1. **Train the Model**: We first train a fine-tunned distilbert and use that to obtain numberical values for the def_text info, then we trained a gradient boosting model22222222 with the dataset.\n",
    "2. **Evaluate Performance**: Measure the modelâ€™s accuracy and performance using cross-validation or other techniques.\n",
    "3. **Generate Predictions**: Use the trained model to predict severity labels for the test dataset and evaluate the model's predictions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Logic for Deriving a Consensus Severity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd               # Data manipulation\n",
    "import numpy as np                # Numerical operations\n",
    "import matplotlib.pyplot as plt    # Plotting\n",
    "import seaborn as sns             # Data visualization\n",
    "import re                          # Regular expressions for text processing\n",
    "from sklearn.model_selection import train_test_split  # Splitting data\n",
    "from sklearn.preprocessing import LabelEncoder         # Label encoding for target variable\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consensus severity saved to datasets/consensus_severity_output.csv\n",
      "Reputation scores saved to datasets/consensus_severity_output_reputation.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_reputation_scores(data):\n",
    "    \"\"\"\n",
    "    Compute reputation scores for all inspectors based on majority agreement.\n",
    "    Inspectors get +1 for each deficiency where their severity matches any majority severity.\n",
    "    \"\"\"\n",
    "    reputation_scores = defaultdict(int)\n",
    "    \n",
    "    # Group by unique deficiency cases\n",
    "    grouped = data.groupby(['VesselId', 'PscInspectionId', 'deficiency_code'])\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # Count occurrences of each severity\n",
    "        severity_counts = Counter(group['annotation_severity'])\n",
    "        max_count = max(severity_counts.values())\n",
    "        \n",
    "        # Get all severities that have the maximum count\n",
    "        majority_severities = {severity for severity, count in severity_counts.items() \n",
    "                             if count == max_count}\n",
    "        \n",
    "        # Update reputation scores for inspectors who chose any majority severity\n",
    "        for _, row in group.iterrows():\n",
    "            if row['annotation_severity'] in majority_severities:\n",
    "                reputation_scores[row['username']] += 1\n",
    "    \n",
    "    return reputation_scores\n",
    "\n",
    "def derive_consensus_severity(group, reputation_scores):\n",
    "    \"\"\"\n",
    "    Derive consensus severity based on majority and reputation scores for tie-breaking.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each severity\n",
    "    severity_counts = Counter(group['annotation_severity'])\n",
    "    max_count = max(severity_counts.values())\n",
    "    \n",
    "    # Get severities with maximum count\n",
    "    majority_severities = {severity for severity, count in severity_counts.items() \n",
    "                         if count == max_count}\n",
    "    \n",
    "    # If there's only one majority severity, return it\n",
    "    if len(majority_severities) == 1:\n",
    "        return majority_severities.pop()\n",
    "    \n",
    "    # For ties, find the inspector with highest reputation among tied severities\n",
    "    highest_rep_score = -1\n",
    "    consensus_severity = None\n",
    "    \n",
    "    # Filter to only look at inspectors who gave majority severities\n",
    "    tied_inspectors = group[group['annotation_severity'].isin(majority_severities)]\n",
    "    \n",
    "    for _, row in tied_inspectors.iterrows():\n",
    "        rep_score = reputation_scores[row['username']]\n",
    "        if rep_score > highest_rep_score:\n",
    "            highest_rep_score = rep_score\n",
    "            consensus_severity = row['annotation_severity']\n",
    "        # If same reputation score, take the higher severity as tie-breaker\n",
    "        elif rep_score == highest_rep_score and row['annotation_severity'] > consensus_severity:\n",
    "            consensus_severity = row['annotation_severity']\n",
    "    \n",
    "    return consensus_severity\n",
    "\n",
    "def process_severity_data(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Main function to process severity data and generate consensus outputs.\n",
    "    \"\"\"\n",
    "    # Read and clean data\n",
    "    data = pd.read_csv(input_file).dropna(subset=['annotation_severity'])\n",
    "    \n",
    "    # First compute reputation scores for all inspectors\n",
    "    reputation_scores = compute_reputation_scores(data)\n",
    "    \n",
    "    # Now derive consensus severities using the pre-computed reputation scores\n",
    "    consensus_severities = []\n",
    "    \n",
    "    grouped = data.groupby(['VesselId', 'PscInspectionId', 'deficiency_code'])\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        consensus_severity = derive_consensus_severity(group, reputation_scores)\n",
    "        \n",
    "        consensus_severities.append({\n",
    "            'VesselId': group['VesselId'].iloc[0],\n",
    "            'PscInspectionId': group['PscInspectionId'].iloc[0],\n",
    "            'deficiency_code': group['deficiency_code'].iloc[0],\n",
    "            'consensus_severity': consensus_severity,\n",
    "            'inspectors': ', '.join(f\"{user} (ID: {annot_id}, Severity: {severity})\"\n",
    "                                  for user, annot_id, severity in \n",
    "                                  zip(group['username'], \n",
    "                                      group['annotation_id'], \n",
    "                                      group['annotation_severity'])),\n",
    "            'inspection_date': group['InspectionDate'].iloc[0],\n",
    "            'VesselGroup': group['VesselGroup'].iloc[0],\n",
    "            'age': group['age'].iloc[0],            \n",
    "             'def_text': group['def_text'].iloc[0]\n",
    "        })\n",
    "    \n",
    "    # Create output dataframes\n",
    "    consensus_df = pd.DataFrame(consensus_severities)\n",
    "    reputation_df = pd.DataFrame(list(reputation_scores.items()),\n",
    "                               columns=['username', 'reputation_score'])\\\n",
    "                               .sort_values(by=['reputation_score', 'username'],\n",
    "                                          ascending=[False, True])\n",
    "    \n",
    "    # Sort consensus dataframe\n",
    "    consensus_df = consensus_df.sort_values(\n",
    "        by=['VesselId', 'PscInspectionId', 'inspection_date'],\n",
    "        ascending=True\n",
    "    )\n",
    "    \n",
    "    # Save to files\n",
    "    consensus_df.to_csv(output_file, index=False)\n",
    "    reputation_df.to_csv(output_file.replace('.csv', '_reputation.csv'), index=False)\n",
    "    \n",
    "    print(f\"Consensus severity saved to {output_file}\")\n",
    "    print(f\"Reputation scores saved to {output_file.replace('.csv', '_reputation.csv')}\")\n",
    "\n",
    "input_file = 'datasets/psc_severity_train.csv'\n",
    "output_file = 'datasets/consensus_severity_output.csv'\n",
    "process_severity_data(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VesselId</th>\n",
       "      <th>PscInspectionId</th>\n",
       "      <th>deficiency_code</th>\n",
       "      <th>consensus_severity</th>\n",
       "      <th>inspectors</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>VesselGroup</th>\n",
       "      <th>age</th>\n",
       "      <th>def_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66646</td>\n",
       "      <td>1695287</td>\n",
       "      <td>2113</td>\n",
       "      <td>High</td>\n",
       "      <td>guru (ID: 42950805, Severity: High), sunil (ID...</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>44.569473</td>\n",
       "      <td>PscInspectionId: 1695287\\n\\nDeficiency/Finding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77681</td>\n",
       "      <td>1671010</td>\n",
       "      <td>3105</td>\n",
       "      <td>High</td>\n",
       "      <td>guru (ID: 46013695, Severity: High), sunil (ID...</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>40.884326</td>\n",
       "      <td>PscInspectionId: 1671010\\n\\nDeficiency/Finding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77681</td>\n",
       "      <td>1671010</td>\n",
       "      <td>18327</td>\n",
       "      <td>Medium</td>\n",
       "      <td>mihail (ID: 42535118, Severity: Medium), raul ...</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>40.884326</td>\n",
       "      <td>PscInspectionId: 1671010\\n\\nDeficiency/Finding...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VesselId  PscInspectionId  deficiency_code consensus_severity  \\\n",
       "0     66646          1695287             2113               High   \n",
       "1     77681          1671010             3105               High   \n",
       "2     77681          1671010            18327             Medium   \n",
       "\n",
       "                                          inspectors inspection_date  \\\n",
       "0  guru (ID: 42950805, Severity: High), sunil (ID...      2023-03-28   \n",
       "1  guru (ID: 46013695, Severity: High), sunil (ID...      2022-12-21   \n",
       "2  mihail (ID: 42535118, Severity: Medium), raul ...      2022-12-21   \n",
       "\n",
       "  VesselGroup        age                                           def_text  \n",
       "0    Dry Bulk  44.569473  PscInspectionId: 1695287\\n\\nDeficiency/Finding...  \n",
       "1    Dry Bulk  40.884326  PscInspectionId: 1671010\\n\\nDeficiency/Finding...  \n",
       "2    Dry Bulk  40.884326  PscInspectionId: 1671010\\n\\nDeficiency/Finding...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the consensus severity\n",
    "df = pd.read_csv(output_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The below function preprocesses the deficiency text data for machine learning.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe containing the deficiency texts\n",
    "    text_column (str): Name of the column containing the deficiency text\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (processed_df, vectorizer)\n",
    "        - processed_df: DataFrame with additional processed text columns\n",
    "        - vectorizer: Fitted TfidfVectorizer for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model training and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) distilbert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for training \n",
    "cleaning + tokenising\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VesselId</th>\n",
       "      <th>PscInspectionId</th>\n",
       "      <th>deficiency_code</th>\n",
       "      <th>consensus_severity</th>\n",
       "      <th>inspectors</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>VesselGroup</th>\n",
       "      <th>age</th>\n",
       "      <th>Detainable Deficiency</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66646</td>\n",
       "      <td>1695287</td>\n",
       "      <td>2113</td>\n",
       "      <td>High</td>\n",
       "      <td>guru (ID: 42950805, Severity: High), sunil (ID...</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>44.569473</td>\n",
       "      <td>No</td>\n",
       "      <td>Hull - cracking Hull - cracking Crack found on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77681</td>\n",
       "      <td>1671010</td>\n",
       "      <td>3105</td>\n",
       "      <td>High</td>\n",
       "      <td>guru (ID: 46013695, Severity: High), sunil (ID...</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>40.884326</td>\n",
       "      <td>No</td>\n",
       "      <td>Lack of maintenance on weathertight hatches/co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VesselId  PscInspectionId  deficiency_code consensus_severity  \\\n",
       "0     66646          1695287             2113               High   \n",
       "1     77681          1671010             3105               High   \n",
       "\n",
       "                                          inspectors inspection_date  \\\n",
       "0  guru (ID: 42950805, Severity: High), sunil (ID...      2023-03-28   \n",
       "1  guru (ID: 46013695, Severity: High), sunil (ID...      2022-12-21   \n",
       "\n",
       "  VesselGroup        age Detainable Deficiency  \\\n",
       "0    Dry Bulk  44.569473                    No   \n",
       "1    Dry Bulk  40.884326                    No   \n",
       "\n",
       "                                       combined_text  \n",
       "0  Hull - cracking Hull - cracking Crack found on...  \n",
       "1  Lack of maintenance on weathertight hatches/co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def extract_deficiency_fields(df):\n",
    "    \"\"\"\n",
    "    Extracts fields from the 'def_text' column of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame containing the 'def_text' column.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with the extracted fields.\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_field(text, field_name):\n",
    "        match = re.search(rf\"{field_name}:\\s*(.*?)(?=\\n[A-Z]|$)\", text, re.DOTALL)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    df['Deficiency/Finding'] = df['def_text'].apply(lambda x: extract_field(x, \"Deficiency/Finding\"))\n",
    "    df['Description Overview'] = df['def_text'].apply(lambda x: extract_field(x, \"Description Overview\"))\n",
    "    df['Immediate Causes'] = df['def_text'].apply(lambda x: extract_field(x, \"Immediate Causes\"))\n",
    "    df['Root Cause Analysis'] = df['def_text'].apply(lambda x: extract_field(x, \"Root Cause Analysis\"))\n",
    "    df['Corrective Action'] = df['def_text'].apply(lambda x: extract_field(x, \"Corrective Action\"))\n",
    "    df['Preventive Action'] = df['def_text'].apply(lambda x: extract_field(x, \"Preventive Action\"))\n",
    "\n",
    "\n",
    "    # Detainable Deficiency (handle differently as it's categorical)\n",
    "    df['Detainable Deficiency'] = df['def_text'].str.extract(r\"Detainable Deficiency:\\s*(.*)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_separate_fields = extract_deficiency_fields(df)\n",
    "\n",
    "df_separate_fields['combined_text'] = (df_separate_fields['Deficiency/Finding'].fillna('') + ' ' +\n",
    "                               df_separate_fields['Description Overview'].fillna('') + ' ' +\n",
    "                               df_separate_fields['Immediate Causes'].fillna('') + ' ' +\n",
    "                               df_separate_fields['Root Cause Analysis'].fillna('') + ' ' +\n",
    "                               df_separate_fields['Corrective Action'].fillna('') + ' ' +\n",
    "                               df_separate_fields['Preventive Action'].fillna('')).str.strip()\n",
    "\n",
    "df_combined_text = df_separate_fields.drop(columns=['Deficiency/Finding', 'Description Overview', 'Immediate Causes', 'Root Cause Analysis', 'Corrective Action', 'Preventive Action', 'def_text'])\n",
    "df_combined_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VesselId</th>\n",
       "      <th>PscInspectionId</th>\n",
       "      <th>deficiency_code</th>\n",
       "      <th>consensus_severity</th>\n",
       "      <th>inspectors</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>VesselGroup</th>\n",
       "      <th>age</th>\n",
       "      <th>Detainable Deficiency</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66646</td>\n",
       "      <td>1695287</td>\n",
       "      <td>2113</td>\n",
       "      <td>High</td>\n",
       "      <td>guru (ID: 42950805, Severity: High), sunil (ID...</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>44.569473</td>\n",
       "      <td>No</td>\n",
       "      <td>hull cracking hull cracking crack found on mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VesselId  PscInspectionId  deficiency_code consensus_severity  \\\n",
       "0     66646          1695287             2113               High   \n",
       "\n",
       "                                          inspectors inspection_date  \\\n",
       "0  guru (ID: 42950805, Severity: High), sunil (ID...      2023-03-28   \n",
       "\n",
       "  VesselGroup        age Detainable Deficiency  \\\n",
       "0    Dry Bulk  44.569473                    No   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  hull cracking hull cracking crack found on mai...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters (optional, but often helpful)\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # Remove special characters and punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    return text.strip()\n",
    "\n",
    "df_combined_text['cleaned_text'] = df_combined_text['combined_text'].apply(clean_text)\n",
    "df_clean_text = df_combined_text.drop(columns=['combined_text'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_clean_text = df_clean_text.dropna(subset=['cleaned_text', 'consensus_severity'])\n",
    "df_clean_text.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenising the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.48.0)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: evaluate in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.27.1)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/huangyuxuan/Library/Python/3.10/lib/python/site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers datasets evaluate huggingface_hub torch\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset # Not used\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report # Used instead of the \"evaluate\" library\n",
    "import torch; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Medium' 'Low' 'Not a deficiency']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8651626596482891beaa652f8dafcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4403 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load DistilBERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 2. Label mapping (same as before)\n",
    "label_mapping = {\"Not a deficiency\": 0, \"Low\": 1, \"Medium\": 2, \"High\": 3}\n",
    "\n",
    "# 3. Print unique labels (same as before)\n",
    "unique_labels = df_clean_text['consensus_severity'].unique()\n",
    "print(unique_labels)\n",
    "\n",
    "# 4. Number of labels\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "# 5. Update labels in the DataFrame\n",
    "df_clean_text['consensus_severity'] = df_clean_text['consensus_severity'].map(label_mapping)\n",
    "\n",
    "# 6. Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df_clean_text[['cleaned_text', 'consensus_severity']])\n",
    "dataset = dataset.rename_column(\"cleaned_text\", \"text\")\n",
    "dataset = dataset.rename_column(\"consensus_severity\", \"label\")\n",
    "\n",
    "# 7. Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 8. Set the format of the dataset\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# 9. Split the dataset into train and test sets\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# 10. Optionally select a smaller subset for faster debugging\n",
    "small_train_dataset = train_dataset.shuffle(seed=42).select(range(1000)) \n",
    "small_eval_dataset = test_dataset.shuffle(seed=42).select(range(200))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the model takes a long time, hence we will only run it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at 'model_large_dataset'. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "\n",
    "# Define the dataset name for saving the model\n",
    "dataset_name = \"large_dataset\"\n",
    "saved_model_path = f'model_{dataset_name}'\n",
    "\n",
    "# Check if the model already exists\n",
    "if not os.path.exists(saved_model_path):\n",
    "    print(f\"Model not found at '{saved_model_path}'. Starting training...\")\n",
    "    \n",
    "    # Load DistilBERT model for sequence classification\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "    \n",
    "    # Load accuracy metric\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        disable_tqdm=False,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=500,\n",
    "        fp16=True\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=small_train_dataset,\n",
    "        eval_dataset=small_eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the trained model\n",
    "    trainer.save_model(saved_model_path)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Training complete. Evaluation results:\", results)\n",
    "else:\n",
    "    print(f\"Model already exists at '{saved_model_path}'. Skipping training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('model_large_dataset')\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use the last hidden state or logits as features\n",
    "        return outputs.logits.numpy().flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VesselId</th>\n",
       "      <th>PscInspectionId</th>\n",
       "      <th>deficiency_code</th>\n",
       "      <th>consensus_severity</th>\n",
       "      <th>inspectors</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>VesselGroup</th>\n",
       "      <th>age</th>\n",
       "      <th>Detainable Deficiency</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66646</td>\n",
       "      <td>1695287</td>\n",
       "      <td>2113</td>\n",
       "      <td>3</td>\n",
       "      <td>guru (ID: 42950805, Severity: High), sunil (ID...</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>44.569473</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.655375</td>\n",
       "      <td>0.390650</td>\n",
       "      <td>1.109482</td>\n",
       "      <td>0.725045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77681</td>\n",
       "      <td>1671010</td>\n",
       "      <td>3105</td>\n",
       "      <td>3</td>\n",
       "      <td>guru (ID: 46013695, Severity: High), sunil (ID...</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>40.884326</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.697097</td>\n",
       "      <td>0.428598</td>\n",
       "      <td>1.209944</td>\n",
       "      <td>0.722074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77681</td>\n",
       "      <td>1671010</td>\n",
       "      <td>18327</td>\n",
       "      <td>2</td>\n",
       "      <td>mihail (ID: 42535118, Severity: Medium), raul ...</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>40.884326</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.414241</td>\n",
       "      <td>0.018993</td>\n",
       "      <td>1.259212</td>\n",
       "      <td>0.793717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83036</td>\n",
       "      <td>1688644</td>\n",
       "      <td>3104</td>\n",
       "      <td>3</td>\n",
       "      <td>ranjit (ID: 46089058, Severity: High), man (ID...</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>38.915811</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.652054</td>\n",
       "      <td>0.793822</td>\n",
       "      <td>0.941590</td>\n",
       "      <td>0.582170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83036</td>\n",
       "      <td>1688644</td>\n",
       "      <td>15150</td>\n",
       "      <td>2</td>\n",
       "      <td>guru (ID: 42436473, Severity: High), sunil (ID...</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>38.915811</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.680373</td>\n",
       "      <td>1.541046</td>\n",
       "      <td>0.847053</td>\n",
       "      <td>0.075584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VesselId  PscInspectionId  deficiency_code  consensus_severity  \\\n",
       "0     66646          1695287             2113                   3   \n",
       "1     77681          1671010             3105                   3   \n",
       "2     77681          1671010            18327                   2   \n",
       "3     83036          1688644             3104                   3   \n",
       "4     83036          1688644            15150                   2   \n",
       "\n",
       "                                          inspectors inspection_date  \\\n",
       "0  guru (ID: 42950805, Severity: High), sunil (ID...      2023-03-28   \n",
       "1  guru (ID: 46013695, Severity: High), sunil (ID...      2022-12-21   \n",
       "2  mihail (ID: 42535118, Severity: Medium), raul ...      2022-12-21   \n",
       "3  ranjit (ID: 46089058, Severity: High), man (ID...      2023-03-02   \n",
       "4  guru (ID: 42436473, Severity: High), sunil (ID...      2023-03-02   \n",
       "\n",
       "  VesselGroup        age Detainable Deficiency     emb_0     emb_1     emb_2  \\\n",
       "0    Dry Bulk  44.569473                    No -2.655375  0.390650  1.109482   \n",
       "1    Dry Bulk  40.884326                    No -2.697097  0.428598  1.209944   \n",
       "2    Dry Bulk  40.884326                    No -2.414241  0.018993  1.259212   \n",
       "3    Dry Bulk  38.915811                    No -2.652054  0.793822  0.941590   \n",
       "4    Dry Bulk  38.915811                    No -2.680373  1.541046  0.847053   \n",
       "\n",
       "      emb_3  \n",
       "0  0.725045  \n",
       "1  0.722074  \n",
       "2  0.793717  \n",
       "3  0.582170  \n",
       "4  0.075584  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Check if embeddings file already exists\n",
    "embeddings_file = 'embeddings.pkl'\n",
    "\n",
    "if os.path.exists(embeddings_file):\n",
    "    # If embeddings already exist, load from file\n",
    "    print(\"Loading precomputed embeddings...\")\n",
    "    with open(embeddings_file, 'rb') as f:\n",
    "        df_for_training = pickle.load(f)\n",
    "else:\n",
    "    # Enable the tqdm progress bar for Pandas apply\n",
    "    tqdm.pandas()\n",
    "\n",
    "    # Generate embeddings for each cleaned_text with progress\n",
    "    df_clean_text['embeddings'] = df_clean_text['cleaned_text'].progress_apply(lambda x: generate_embeddings(x))\n",
    "\n",
    "    # Flatten the embeddings into separate columns (assuming embeddings are vectors)\n",
    "    embedding_dim = len(df_clean_text['embeddings'].iloc[0])  # This is the size of the embedding vector\n",
    "    embedding_df = pd.DataFrame(df_clean_text['embeddings'].to_list(), columns=[f'emb_{i}' for i in range(embedding_dim)])\n",
    "\n",
    "    # Concatenate the flattened embeddings with the original DataFrame\n",
    "    df_for_training = pd.concat([df_clean_text.reset_index(drop=True), embedding_df], axis=1)\n",
    "\n",
    "    # Drop the 'cleaned_text' and 'embeddings' columns (optional, depending on what you need)\n",
    "    df_for_training = df_for_training.drop(columns=['cleaned_text', 'embeddings'])\n",
    "\n",
    "    # Save the resulting dataframe with embeddings\n",
    "    with open(embeddings_file, 'wb') as f:\n",
    "        pickle.dump(df_for_training, f)\n",
    "\n",
    "    # Optionally, save as CSV\n",
    "    # df_for_training.to_csv('df_for_training_with_embeddings.csv', index=False)\n",
    "\n",
    "df_for_training.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in consensus_severity: 0\n",
      "Missing values after encoding: 0\n",
      "Data shape after dropping NaNs: (4403, 4)\n",
      "Shape after encoding categorical variables: (4403, 445)\n",
      "Training set shape: X_train=(3962, 445), y_train=(3962,)\n",
      "Test set shape: X_test=(441, 445), y_test=(441,)\n",
      "Accuracy: 0.4308390022675737\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Not a deficiency       0.00      0.00      0.00         2\n",
      "             Low       0.43      0.73      0.54       181\n",
      "          Medium       0.39      0.28      0.32       163\n",
      "            High       0.65      0.14      0.23        95\n",
      "\n",
      "        accuracy                           0.43       441\n",
      "       macro avg       0.37      0.29      0.27       441\n",
      "    weighted avg       0.46      0.43      0.39       441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangyuxuan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/huangyuxuan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/huangyuxuan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "# data = pd.read_csv('datasets/consensus_severity_output.csv')\n",
    "data = df_for_training\n",
    "\n",
    "# Check for missing values in 'consensus_severity'\n",
    "print(f\"Missing values in consensus_severity: {data['consensus_severity'].isnull().sum()}\")\n",
    "\n",
    "# Check if there are NaN values in the 'severity_encoded' column after mapping\n",
    "print(f\"Missing values after encoding: {data['consensus_severity'].isnull().sum()}\")\n",
    "\n",
    "# Features and target\n",
    "X = data[['age', 'VesselGroup', 'deficiency_code']]\n",
    "y = data['consensus_severity']\n",
    "\n",
    "# Combine features and target for further processing\n",
    "data_combined = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Drop rows where the target column (y) has NaN\n",
    "data_combined = data_combined.dropna(subset=['consensus_severity'])\n",
    "\n",
    "# Print to check how many rows remain after dropping NaNs\n",
    "print(f\"Data shape after dropping NaNs: {data_combined.shape}\")\n",
    "\n",
    "# Split back into features (X) and target (y)\n",
    "X = data_combined.drop('consensus_severity', axis=1)\n",
    "y = data_combined['consensus_severity']\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, columns=['VesselGroup', 'deficiency_code'], drop_first=True)\n",
    "\n",
    "# Print to check the shape after encoding categorical variables\n",
    "print(f\"Shape after encoding categorical variables: {X.shape}\")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print the shape of training and testing sets\n",
    "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "# Model setup\n",
    "model2 = XGBClassifier(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    learning_rate=0.1,     # Step size shrinkage\n",
    "    max_depth=6,           # Max depth of trees\n",
    "    subsample=0.8,         # Fraction of samples used for training\n",
    "    colsample_bytree=0.8,  # Fraction of features used per tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict class\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Predict probabilities (optional, for metrics like AUC-ROC)\n",
    "y_pred_proba = model2.predict_proba(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not a deficiency', 'Low', 'Medium', 'High']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1101/1101 [00:52<00:00, 20.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PscInspectionId</th>\n",
       "      <th>deficiency_code</th>\n",
       "      <th>InspectionDate</th>\n",
       "      <th>VesselId</th>\n",
       "      <th>PscAuthorityId</th>\n",
       "      <th>PortId</th>\n",
       "      <th>VesselGroup</th>\n",
       "      <th>age</th>\n",
       "      <th>Detainable Deficiency</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1802364</td>\n",
       "      <td>14402</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>293691</td>\n",
       "      <td>9</td>\n",
       "      <td>936</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>9.593429</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.428447</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>1.280959</td>\n",
       "      <td>0.773754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1736765</td>\n",
       "      <td>10199</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>272075</td>\n",
       "      <td>9</td>\n",
       "      <td>5237</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>25.210130</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.809258</td>\n",
       "      <td>1.883787</td>\n",
       "      <td>0.035624</td>\n",
       "      <td>-0.578579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1787907</td>\n",
       "      <td>18204</td>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>302667</td>\n",
       "      <td>1</td>\n",
       "      <td>953</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>5.793292</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.777685</td>\n",
       "      <td>1.192926</td>\n",
       "      <td>0.842268</td>\n",
       "      <td>0.342324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1691176</td>\n",
       "      <td>14108</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>288591</td>\n",
       "      <td>7</td>\n",
       "      <td>1439</td>\n",
       "      <td>Oil</td>\n",
       "      <td>12.446270</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.573310</td>\n",
       "      <td>0.450111</td>\n",
       "      <td>1.206649</td>\n",
       "      <td>0.735640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1712454</td>\n",
       "      <td>5109</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>290457</td>\n",
       "      <td>2</td>\n",
       "      <td>1366</td>\n",
       "      <td>Dry Bulk</td>\n",
       "      <td>11.731691</td>\n",
       "      <td>No</td>\n",
       "      <td>-2.717867</td>\n",
       "      <td>0.619949</td>\n",
       "      <td>1.291194</td>\n",
       "      <td>0.561986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PscInspectionId  deficiency_code InspectionDate  VesselId  PscAuthorityId  \\\n",
       "0          1802364            14402     2024-04-05    293691               9   \n",
       "1          1736765            10199     2023-08-17    272075               9   \n",
       "2          1787907            18204     2024-02-15    302667               1   \n",
       "3          1691176            14108     2023-03-13    288591               7   \n",
       "4          1712454             5109     2023-05-26    290457               2   \n",
       "\n",
       "   PortId VesselGroup        age Detainable Deficiency     emb_0     emb_1  \\\n",
       "0     936    Dry Bulk   9.593429                    No -2.428447 -0.004113   \n",
       "1    5237    Dry Bulk  25.210130                    No -1.809258  1.883787   \n",
       "2     953    Dry Bulk   5.793292                    No -2.777685  1.192926   \n",
       "3    1439         Oil  12.446270                    No -2.573310  0.450111   \n",
       "4    1366    Dry Bulk  11.731691                    No -2.717867  0.619949   \n",
       "\n",
       "      emb_2     emb_3  \n",
       "0  1.280959  0.773754  \n",
       "1  0.035624 -0.578579  \n",
       "2  0.842268  0.342324  \n",
       "3  1.206649  0.735640  \n",
       "4  1.291194  0.561986  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('datasets/psc_severity_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "test_separate_fields = extract_deficiency_fields(test)\n",
    "\n",
    "test_separate_fields['combined_text'] = (test_separate_fields['Deficiency/Finding'].fillna('') + ' ' +\n",
    "                               test_separate_fields['Description Overview'].fillna('') + ' ' +\n",
    "                               test_separate_fields['Immediate Causes'].fillna('') + ' ' +\n",
    "                               test_separate_fields['Root Cause Analysis'].fillna('') + ' ' +\n",
    "                               test_separate_fields['Corrective Action'].fillna('') + ' ' +\n",
    "                               test_separate_fields['Preventive Action'].fillna('')).str.strip()\n",
    "\n",
    "test_combined_text = test_separate_fields.drop(columns=['Deficiency/Finding', 'Description Overview', 'Immediate Causes', 'Root Cause Analysis', 'Corrective Action', 'Preventive Action', 'def_text'])\n",
    "test_combined_text.head(2)\n",
    "\n",
    "test_combined_text['cleaned_text'] = test_combined_text['combined_text'].apply(clean_text)\n",
    "test_clean_text = test_combined_text.drop(columns=['combined_text'])\n",
    "\n",
    "\n",
    "test_clean_text = test_clean_text.dropna(subset=['cleaned_text'])\n",
    "test_clean_text.head(1)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Check if embeddings file already exists\n",
    "embeddings_file = 'embeddings_test.pkl'\n",
    "\n",
    "if os.path.exists(embeddings_file):\n",
    "    # If embeddings already exist, load from file\n",
    "    print(\"Loading precomputed embeddings...\")\n",
    "    with open(embeddings_file, 'rb') as f:\n",
    "        test_for_training = pickle.load(f)\n",
    "else:\n",
    "    # Enable the tqdm progress bar for Pandas apply\n",
    "    tqdm.pandas()\n",
    "\n",
    "    # Generate embeddings for each cleaned_text with progress\n",
    "    test_clean_text['embeddings'] = test_clean_text['cleaned_text'].progress_apply(lambda x: generate_embeddings(x))\n",
    "\n",
    "    # Flatten the embeddings into separate columns (assuming embeddings are vectors)\n",
    "    embedding_dim = len(test_clean_text['embeddings'].iloc[0])  # This is the size of the embedding vector\n",
    "    embedding = pd.DataFrame(test_clean_text['embeddings'].to_list(), columns=[f'emb_{i}' for i in range(embedding_dim)])\n",
    "\n",
    "    # Concatenate the flattened embeddings with the original DataFrame\n",
    "    test_for_training = pd.concat([test_clean_text.reset_index(drop=True), embedding], axis=1)\n",
    "\n",
    "    # Drop the 'cleaned_text' and 'embeddings' columns (optional, depending on what you need)\n",
    "    test_for_training = test_for_training.drop(columns=['cleaned_text', 'embeddings'])\n",
    "\n",
    "    # Save the resulting dataframe with embeddings\n",
    "    with open(embeddings_file, 'wb') as f:\n",
    "        pickle.dump(test_for_training, f)\n",
    "\n",
    "\n",
    "test_for_training.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1101, 13)\n",
      "  Predicted_Severity\n",
      "0                Low\n",
      "1             Medium\n",
      "2               High\n",
      "3                Low\n",
      "4                Low\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(f\"Test data shape: {test_for_training.shape}\")\n",
    "\n",
    "X_test_data = test_for_training[['age', 'VesselGroup', 'deficiency_code', 'emb_0', 'emb_1', 'emb_2', 'emb_3']]\n",
    "\n",
    "X_test_data = pd.get_dummies(X_test_data, columns=['VesselGroup', 'deficiency_code'], drop_first=True)\n",
    "\n",
    "X_test_data = X_test_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "y_pred_test = model2.predict(X_test_data)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Predicted_Severity': y_pred_test\n",
    "})\n",
    "\n",
    "severity_mapping_inv = {0: 'Not a deficiency', 1: 'Low', 2: 'Medium', 3: 'High'}\n",
    "predictions_df['Predicted_Severity'] = predictions_df['Predicted_Severity'].map(severity_mapping_inv)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('MaritimeHackathon2025_SeverityPredictions_SQUARE.csv', index=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(predictions_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
